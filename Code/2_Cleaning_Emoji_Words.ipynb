{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "C0XRzbaEQr88"
      },
      "outputs": [],
      "source": [
        "!pip install ydata-profiling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install indoNLP"
      ],
      "metadata": {
        "id": "23R9kRjrR-Zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "id": "C-yINYA5SKFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "from unidecode import unidecode\n",
        "import unicodedata\n",
        "\n",
        "from indoNLP.preprocessing import replace_slang, replace_word_elongation, emoji_to_words"
      ],
      "metadata": {
        "id": "BMWLztZESN6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('dataset.csv', encoding='utf-8')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "qvxS-zx1TlHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check NaN Rows"
      ],
      "metadata": {
        "id": "UD--VuigUjgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_nan(text):\n",
        "    return pd.isna(text)"
      ],
      "metadata": {
        "id": "OaNH71HIVeYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_check_nan = df.copy()\n",
        "df_check_nan['is_nan'] = df_check_nan['content'].apply(is_nan)\n",
        "\n",
        "df_check_nan[df_check_nan['is_nan'] == True]"
      ],
      "metadata": {
        "id": "1YgnGktzWJuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Non-ASCII Characters"
      ],
      "metadata": {
        "id": "MXLiwV9UWL8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_non_ascii(text):\n",
        "  patt = re.compile(r\"[a-zA-Z0-9]\", re.UNICODE)\n",
        "\n",
        "  if patt.search(text):\n",
        "    return False\n",
        "\n",
        "  return True"
      ],
      "metadata": {
        "id": "W5mBH3Jdqo5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_non_ascii = df.copy(deep = True)\n",
        "df_non_ascii['Non-ASCII'] = df_non_ascii['content'].apply(check_non_ascii)\n",
        "\n",
        "df_non_ascii[df_non_ascii['Non-ASCII'] == True]"
      ],
      "metadata": {
        "id": "PU1yiV5Gqs8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['content'].iloc[2329]"
      ],
      "metadata": {
        "id": "TmidO5avW229"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_font(text):\n",
        "  text = unidecode(str(text))\n",
        "  text = unicodedata.normalize('NFKC', text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "tSscWUyVXDbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows_to_normalize = [370, 2329, 5448, 7097, 12456]\n",
        "column_to_normalize = 'content'"
      ],
      "metadata": {
        "id": "AvU1HSjIXpzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[rows_to_normalize, column_to_normalize] = df.loc[rows_to_normalize, column_to_normalize].apply(normalize_font)"
      ],
      "metadata": {
        "id": "1NviK7N8YfGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['content'].iloc[2329]"
      ],
      "metadata": {
        "id": "O5LNKy4kXuk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Text Cleaning"
      ],
      "metadata": {
        "id": "sRI-NsCCXXgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def emoji_alias(text):\n",
        "  temp = emoji_to_words(text, delimiter = (\" \", \" \"))\n",
        "  return \" \".join(word.replace(\"_\", \" \") for word in temp.split())"
      ],
      "metadata": {
        "id": "kVGrmCurXENO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_repetitive_symbols(text):\n",
        "  return re.sub(r'([^\\w\\s])\\1+', r'\\1', text)"
      ],
      "metadata": {
        "id": "3QSsrppJauG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning(text):\n",
        "  if not isinstance(text, str):\n",
        "        return text\n",
        "\n",
        "  text_clean = text.lower()\n",
        "  text_clean = re.sub(r'\\s+', ' ', text_clean)\n",
        "  text_clean = replace_slang(text_clean)\n",
        "  text_clean = replace_word_elongation(text_clean)\n",
        "  text_clean = emoji_alias(text_clean)\n",
        "  text_clean = remove_repetitive_symbols(text_clean)\n",
        "  text_clean = text_clean.strip()\n",
        "\n",
        "  return text_clean"
      ],
      "metadata": {
        "id": "7bUfd0XPZTGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = df.copy(deep=True)\n",
        "df_cleaned['cleaned_content'] = df_cleaned['content'].apply(cleaning)"
      ],
      "metadata": {
        "id": "Sj-BkOXCZiXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['content'].iloc[1140])\n",
        "print(df_cleaned['cleaned_content'].iloc[1140])"
      ],
      "metadata": {
        "id": "ffpuGZEqZgtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['content'].iloc[10556])\n",
        "print(df_cleaned['cleaned_content'].iloc[10556])"
      ],
      "metadata": {
        "id": "gEAx0KAOaJxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['content'].iloc[12701])\n",
        "print(df_cleaned['cleaned_content'].iloc[12701])"
      ],
      "metadata": {
        "id": "2Nax9rxkhqur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Word Occurence + Missed Normalization"
      ],
      "metadata": {
        "id": "bF8_lPHhcxIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re"
      ],
      "metadata": {
        "id": "a61D9ocqdBrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_counts(df, column):\n",
        "  all_text = \" \".join(df[column].dropna().astype(str)).lower()\n",
        "  words = re.findall(r'\\b\\w+\\b', all_text)\n",
        "  word_counts = Counter(words)\n",
        "\n",
        "  return word_counts"
      ],
      "metadata": {
        "id": "hqcPuD78c24o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts = get_word_counts(df_cleaned, 'cleaned_content')"
      ],
      "metadata": {
        "id": "Rtnp9pI3hIhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_word_counts = pd.DataFrame(word_counts.items(), columns=['word', 'count']).sort_values(by='count', ascending=False)\n",
        "df_word_counts.to_csv('word_counts.csv', index=False)"
      ],
      "metadata": {
        "id": "Qz1pl_bohKxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_dict = {\n",
        "  'enggak': 'tidak',\n",
        "  'apk': 'aplikasi',\n",
        "  'good': 'bagus',\n",
        "  'eror': 'error',\n",
        "  'kalo': 'kalau',\n",
        "  'kagak': 'tidak',\n",
        "  'uninstal': 'uninstall',\n",
        "  'dl': 'dulu',\n",
        "  'apps': 'aplikasi',\n",
        "  'n': 'dan',\n",
        "  'tije': 'transjakarta',\n",
        "  'ticket': 'tiket',\n",
        "  'pengin': 'ingin',\n",
        "  'muter': 'putar',\n",
        "  'apl': 'aplikasi',\n",
        "  'plis': 'tolong',\n",
        "  'ful': 'penuh'\n",
        "}"
      ],
      "metadata": {
        "id": "hqeDbQZUhAu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_words(text, norm_dict):\n",
        "  for k, v in norm_dict.items():\n",
        "    text = re.sub(r'\\b' + re.escape(k) + r'\\b', v, text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "2CcBl_BFhCh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['cleaned_content'] = df_cleaned['cleaned_content'].apply(lambda x: normalize_words(x, normalization_dict))"
      ],
      "metadata": {
        "id": "t7YMSA1KhWWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['content'].iloc[1273])\n",
        "print(df_cleaned['cleaned_content'].iloc[10556])"
      ],
      "metadata": {
        "id": "br7IWsfShmVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['content'].iloc[12701])\n",
        "print(df_cleaned['cleaned_content'].iloc[12701])"
      ],
      "metadata": {
        "id": "6rpmX2s2i2Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Emoji"
      ],
      "metadata": {
        "id": "Qq2IujLpUhoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_pattern = re.compile(\n",
        "    \"[\\U0001F600-\\U0001F64F\"\n",
        "    \"\\U0001F300-\\U0001F5FF\"\n",
        "    \"\\U0001F680-\\U0001F6FF\"\n",
        "    \"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
        "    \"\\U00002700-\\U000027BF\"  # dingbats\n",
        "    \"\\U0001F900-\\U0001F9FF\"  # supplemental symbols\n",
        "    \"\\U00002600-\\U000026FF\"  # misc symbols\n",
        "    \"]+\"\n",
        ")\n",
        "\n",
        "df_emoji = df[df['content'].str.contains(emoji_pattern, na=False)]\n",
        "df_emoji"
      ],
      "metadata": {
        "id": "Wg4Jw5QWSnEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Labeled Sentiment"
      ],
      "metadata": {
        "id": "ctZpe2-ljoje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['sentiment'] = df['score'].apply(\n",
        "    lambda x:\n",
        "    'negative' if x < 3\n",
        "    else 'neutral' if x == 3\n",
        "    else 'positive'\n",
        ")"
      ],
      "metadata": {
        "id": "5cvYPsdQjqsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save to .csv"
      ],
      "metadata": {
        "id": "qzsJe0T75eQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.to_csv('emoji_words.csv', index = False)"
      ],
      "metadata": {
        "id": "wkd345OwjuKJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}