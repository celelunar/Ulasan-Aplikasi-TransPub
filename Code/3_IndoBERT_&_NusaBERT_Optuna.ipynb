{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qKwwrTUbCEYY",
        "Pec1x1_miPTZ",
        "_5u4alfdjrYL",
        "5j6con3bB-Vz",
        "aeQcYeyeCANe"
      ],
      "machine_shape": "hm",
      "gpuType": "L4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPlXBhP1Nocu"
      },
      "source": [
        "# 1. Install and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxFd_Nmq1MAK"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRLbLRTtKSq4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "from copy import deepcopy\n",
        "from pathlib import Path\n",
        "import time\n",
        "from google.colab import drive\n",
        "import gc\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    BertForSequenceClassification,\n",
        "    AlbertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "from torch.optim import AdamW\n",
        "\n",
        "import optuna\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import optuna.visualization.matplotlib as opviz_mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import warnings\n",
        "\n",
        "from optuna.importance import FanovaImportanceEvaluator\n",
        "from optuna.importance import get_param_importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6ZDKwJfNrdL"
      },
      "source": [
        "# 2. Environment Settings and Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKwwrTUbCEYY"
      },
      "source": [
        "## 2.1. Set Seed for Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42"
      ],
      "metadata": {
        "id": "g6KaZIz1UUwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22_c826efQA1"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cuda.matmul.allow_tf32 = False\n",
        "    torch.backends.cudnn.allow_tf32 = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "DKcdAgC5UXuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = SEED + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n"
      ],
      "metadata": {
        "id": "iZLf5SjaUSua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator(seed):\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(seed)\n",
        "    return g"
      ],
      "metadata": {
        "id": "Yeokw4ecUdYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pec1x1_miPTZ"
      },
      "source": [
        "## 2.2. Set GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q13sA8tEiRpl"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRNNX-IxiSua"
      },
      "source": [
        "## 2.3. Manage Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMZT6e6Kiuv2"
      },
      "source": [
        "### 2.3.1. Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QArK99vYixSF"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck2cH-kViyOR"
      },
      "source": [
        "### 2.3.2. Set Folder Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsFYWGlci9zI"
      },
      "outputs": [],
      "source": [
        "# Datasets\n",
        "READ_PATH = '/content/drive/MyDrive/Bach_Thesis/Dataset/'\n",
        "\n",
        "# Models\n",
        "SAVE_ROOT = \"/content/drive/MyDrive/Bach_Thesis/Models/SA_Optuna\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5u4alfdjrYL"
      },
      "source": [
        "## 2.4. Initialize Global Parameter and Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXNA-w-Zgq-M"
      },
      "outputs": [],
      "source": [
        "NUM_LABELS = 2\n",
        "LABELS = [0,1]\n",
        "TARGET_NAMES = ['negative' ,'positive']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5. Initialize Datasets"
      ],
      "metadata": {
        "id": "TpjNx-RVaOVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_xy(df, text_col=\"cleaned_content\", label_col=\"sentiment\"):\n",
        "    X = df[text_col].tolist()\n",
        "    y = df[label_col].tolist()\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "HWPbDAmZi_mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_ori = pd.read_csv(f\"{READ_PATH}Train2lab.csv\")\n",
        "df_train_ros = pd.read_csv(f\"{READ_PATH}Train_ROS2lab.csv\")\n",
        "df_train_ros_ncl = pd.read_csv(f\"{READ_PATH}Train_ROS_NCL2lab.csv\")\n",
        "df_val = pd.read_csv(f\"{READ_PATH}Validation2lab.csv\")\n",
        "df_test = pd.read_csv(f\"{READ_PATH}Test2lab.csv\")"
      ],
      "metadata": {
        "id": "5e4wRFo9aPy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = extract_xy(df_train_ori)\n",
        "X_train_ros, y_train_ros = extract_xy(df_train_ros)\n",
        "X_train_ros_ncl, y_train_ros_ncl = extract_xy(df_train_ros_ncl)\n",
        "X_val, y_val     = extract_xy(df_val)\n",
        "X_test, y_test   = extract_xy(df_test)"
      ],
      "metadata": {
        "id": "SwWYIY_ai2TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = torch.tensor(\n",
        "    compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train),\n",
        "    dtype=torch.float\n",
        ").to(DEVICE)\n",
        "\n",
        "class_weights_ros = torch.tensor(\n",
        "    compute_class_weight(class_weight='balanced', classes=np.unique(y_train_ros), y=y_train_ros),\n",
        "    dtype=torch.float\n",
        ").to(DEVICE)\n",
        "\n",
        "class_weights_ros_ncl = torch.tensor(\n",
        "    compute_class_weight(class_weight='balanced', classes=np.unique(y_train_ros_ncl), y=y_train_ros_ncl),\n",
        "    dtype=torch.float\n",
        ").to(DEVICE)"
      ],
      "metadata": {
        "id": "ontzSSCwaQ_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Helper Functions"
      ],
      "metadata": {
        "id": "uo2WZ0a7aU4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = int(df_train_ori['cleaned_content'].str.split().str.len().max())\n",
        "MAX_LEN"
      ],
      "metadata": {
        "id": "fIrvauNvaXEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TXqpubQRSD1"
      },
      "source": [
        "## 3.1. Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCVKQf6kRLuK"
      },
      "outputs": [],
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = list(texts)\n",
        "        self.labels = list(labels)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDagSSF3RXSM"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
        "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
        "    labels = torch.stack([item['labels'] for item in batch])\n",
        "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "331UUIuWRdyr"
      },
      "source": [
        "## 3.2. Initialization Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQOLwgAkRhAR"
      },
      "outputs": [],
      "source": [
        "def init_model_and_tokenizer(MODEL_NAME, num_labels=NUM_LABELS, hidden_dropout_prob=None, attention_dropout_prob=None):\n",
        "    low = MODEL_NAME.lower()\n",
        "    model_kwargs = {}\n",
        "\n",
        "    if hidden_dropout_prob is not None:\n",
        "        model_kwargs['hidden_dropout_prob'] = float(hidden_dropout_prob)\n",
        "    if attention_dropout_prob is not None:\n",
        "        model_kwargs['attention_probs_dropout_prob'] = float(attention_dropout_prob)\n",
        "\n",
        "    if \"lite\" in low:\n",
        "        model = AlbertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels, **model_kwargs)\n",
        "        tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "    elif \"nusabert\" in low:\n",
        "        model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels, **model_kwargs)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
        "    else:\n",
        "        model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels, **model_kwargs)\n",
        "        tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38LdZa0IR7Gc"
      },
      "source": [
        "## 3.4. Create Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BW4MDhwSR_dn"
      },
      "outputs": [],
      "source": [
        "def create_classification_report(y_true, y_pred):\n",
        "    cr = classification_report(\n",
        "        y_true, y_pred,\n",
        "        labels=LABELS,\n",
        "        target_names=TARGET_NAMES,\n",
        "        zero_division=0,\n",
        "        output_dict=True\n",
        "    )\n",
        "    df_cr = pd.DataFrame(cr).transpose().reset_index()\n",
        "    df_cr = df_cr.rename(columns={'index': 'label'})\n",
        "\n",
        "    for col in df_cr.select_dtypes(include=['float']).columns:\n",
        "        df_cr[col] = df_cr[col].apply(lambda x: round(x, 4))\n",
        "\n",
        "    return df_cr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SxQYlG9SB0a"
      },
      "source": [
        "## 3.5. Create Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEIoL4QfSFMd"
      },
      "outputs": [],
      "source": [
        "def create_confusion_matrix(y_true, y_pred, save_path_png):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=TARGET_NAMES, yticklabels=TARGET_NAMES)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path_png, dpi=150)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.6. Training and Validation"
      ],
      "metadata": {
        "id": "rAcWNiN3aikF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_validate_model(model, train_loader, val_loader, optimizer, scheduler, loss_fn, device):\n",
        "    # TRAIN\n",
        "    model.train()\n",
        "    total_train_loss = 0.0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        loss = loss_fn(outputs.logits, labels)\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    # VAL\n",
        "    model.eval()\n",
        "    total_val_loss = 0.0\n",
        "    val_preds, val_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "\n",
        "            loss = loss_fn(outputs.logits, labels)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average=\"weighted\")\n",
        "\n",
        "    return val_f1, avg_train_loss, avg_val_loss"
      ],
      "metadata": {
        "id": "fU6qr2jGavT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.7. Evaluation"
      ],
      "metadata": {
        "id": "jJgnDuWBdFHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, loader, device):\n",
        "    preds, trues = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            preds.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
        "            trues.extend(labels.cpu().numpy())\n",
        "    return preds, trues"
      ],
      "metadata": {
        "id": "2U8eMPiNdYxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_summary(summary):\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"✅ Model Training Summary\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Model Name: {summary['model_name']}\")\n",
        "    print(f\"Train Size: {summary['n_train']}\")\n",
        "    print(f\"Validation Size: {summary['n_val']}\")\n",
        "    print(f\"Test Size: {summary['n_test']}\")\n",
        "    print(\"-\"*40)\n",
        "    print(f\"Train Weighted F1: {summary['train_weighted_f1']:.4f}\")\n",
        "    print(f\"Validation Weighted F1: {summary['val_weighted_f1']:.4f}\")\n",
        "    print(f\"Test Weighted F1: {summary['test_weighted_f1']:.4f}\")\n",
        "    print(\"-\"*40)\n",
        "    print(f\"Train Accuracy: {summary['train_accuracy']:.4f}\")\n",
        "    print(f\"Validation Accuracy: {summary['val_accuracy']:.4f}\")\n",
        "    print(f\"Test Accuracy: {summary['test_accuracy']:.4f}\")\n",
        "    print(\"=\"*40)"
      ],
      "metadata": {
        "id": "ox9mYHCtDp4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.8. Optuna"
      ],
      "metadata": {
        "id": "BnN13esqdcYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial, model_name, X_train, y_train, X_val, y_val, class_weights):\n",
        "    seed_everything(SEED)\n",
        "\n",
        "    # SEARCH SPACE\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 5e-5, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
        "    epochs = trial.suggest_int(\"epochs\", 3, 10)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 0.1, log=True)\n",
        "    warmup_ratio = trial.suggest_float(\"warmup_ratio\", 0.0, 0.2)\n",
        "    hidden_dropout_prob = trial.suggest_float(\"hidden_dropout_prob\", 0.1, 0.4, log=True)\n",
        "    attention_dropout_prob = trial.suggest_float(\"attention_dropout_prob\", 0.1, 0.4, log=True)\n",
        "\n",
        "    # INITIALIZATIONS\n",
        "    model, tokenizer = init_model_and_tokenizer(\n",
        "        model_name,\n",
        "        num_labels=NUM_LABELS,\n",
        "        hidden_dropout_prob=hidden_dropout_prob,\n",
        "        attention_dropout_prob=attention_dropout_prob\n",
        "    )\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        SentimentDataset(X_train, y_train, tokenizer, max_len=MAX_LEN),\n",
        "        batch_size=batch_size, shuffle=True, collate_fn=collate_fn,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=make_generator(SEED)\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        SentimentDataset(X_val, y_val, tokenizer, max_len=MAX_LEN),\n",
        "        batch_size=batch_size, shuffle=False, collate_fn=collate_fn,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=make_generator(SEED)\n",
        "    )\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    total_steps = len(train_loader) * epochs\n",
        "    warmup_steps = int(total_steps * warmup_ratio)\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=warmup_steps,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    history = []\n",
        "\n",
        "    # TRAIN OPTUNA\n",
        "    for epoch in range(epochs):\n",
        "        val_f1, train_loss, val_loss = train_validate_model(model, train_loader, val_loader, optimizer, scheduler, loss_fn, DEVICE)\n",
        "\n",
        "        history.append({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": float(train_loss),\n",
        "            \"val_loss\": float(val_loss),\n",
        "            \"val_weighted_f1\": float(val_f1)\n",
        "        })\n",
        "\n",
        "        trial.report(val_f1, epoch)\n",
        "\n",
        "        if trial.should_prune():\n",
        "            trial.set_user_attr(\"history\", history)\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    trial.set_user_attr(\"history\", history)\n",
        "\n",
        "    del model, tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return val_f1"
      ],
      "metadata": {
        "id": "v77PPaLBde_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_optuna_for_model(model_name, X_train, y_train, X_val, y_val class_weights, n_trials, save_root, dataset_name\n",
        "):\n",
        "    model_dir = model_name.replace(\"/\", \"_\")\n",
        "\n",
        "    # STORAGE INITIALIZATION\n",
        "    experiment_dir = Path(save_root) / model_dir / dataset_name\n",
        "    optuna_dir = experiment_dir / \"optuna_study\"\n",
        "    optuna_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    storage_path = optuna_dir / \"study.db\"\n",
        "    study_name_path = optuna_dir / \"study_name.txt\"\n",
        "\n",
        "    storage_uri = f\"sqlite:///{storage_path}\"\n",
        "\n",
        "    # LOAD/CREATE STUDY\n",
        "    if storage_path.exists() and study_name_path.exists():\n",
        "        # Resume existing study\n",
        "        study_name = study_name_path.read_text().strip()\n",
        "        print(f\"Resuming Optuna study: {study_name}\")\n",
        "        study = optuna.load_study(\n",
        "            study_name=study_name,\n",
        "            storage=storage_uri\n",
        "        )\n",
        "    else:\n",
        "        study_name = f\"opt_{model_dir}_{dataset_name}\"\n",
        "        print(f\"Creating Optuna study: {study_name}\")\n",
        "\n",
        "        study_name_path.write_text(study_name)\n",
        "\n",
        "        sampler = optuna.samplers.TPESampler(seed=SEED)\n",
        "\n",
        "        study = optuna.create_study(\n",
        "            study_name=study_name,\n",
        "            direction=\"maximize\",\n",
        "            sampler=sampler,\n",
        "            storage=storage_uri,\n",
        "            load_if_exists=True\n",
        "        )\n",
        "\n",
        "    # OPTUNA OPTIMIZATION (OBJ. FUNCTION)\n",
        "    study.optimize(\n",
        "        lambda trial: objective(\n",
        "            trial,\n",
        "            model_name,\n",
        "            X_train, y_train,\n",
        "            X_val, y_val,\n",
        "            class_weights\n",
        "        ),\n",
        "        n_trials=n_trials\n",
        "    )\n",
        "\n",
        "    print(f\"BEST weighted F1 = {study.best_value}\")\n",
        "    print(\"BEST hyperparameters:\")\n",
        "    print(study.best_params)\n",
        "\n",
        "    return study.best_params"
      ],
      "metadata": {
        "id": "yNgebmddhX0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('default')\n",
        "warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning)\n",
        "\n",
        "\n",
        "def hp_importance_graph(save_root, model_name, dataset_name):\n",
        "    model_dir = model_name.replace(\"/\", \"_\")\n",
        "    experiment_dir = Path(save_root) / model_dir / dataset_name\n",
        "    optuna_dir = experiment_dir / \"optuna_study\"\n",
        "    storage_path = optuna_dir / \"study.db\"\n",
        "    study_name_path = optuna_dir / \"study_name.txt\"\n",
        "    storage_uri = f\"sqlite:///{storage_path}\"\n",
        "\n",
        "    if storage_path.exists() and study_name_path.exists():\n",
        "        study_name = study_name_path.read_text().strip()\n",
        "        print(f\"Loading existing Optuna study: {study_name}\")\n",
        "\n",
        "        try:\n",
        "            loaded_study = optuna.load_study(\n",
        "                study_name=study_name,\n",
        "                storage=storage_uri\n",
        "            )\n",
        "\n",
        "            # CALCULATE IMPORTANCE\n",
        "            importance_evaluator = FanovaImportanceEvaluator(seed=SEED)\n",
        "\n",
        "            ax = opviz_mpl.plot_param_importances(\n",
        "                loaded_study,\n",
        "                evaluator=importance_evaluator, evaluator\n",
        "                target=lambda t: t.values[0],\n",
        "                target_name='Objective'\n",
        "            )\n",
        "\n",
        "            fig = ax.figure\n",
        "\n",
        "            # PLOT\n",
        "            num_params = len(ax.patches)\n",
        "            cmap = plt.colormaps['berlin']\n",
        "            colors = [cmap(i/num_params) for i in range(num_params)]\n",
        "            for i, patch in enumerate(ax.patches):\n",
        "                patch.set_facecolor(colors[i])\n",
        "\n",
        "            ax.set_facecolor('white')\n",
        "            fig.set_facecolor('white')\n",
        "\n",
        "            ax.set_title('')\n",
        "            fig.texts = []\n",
        "\n",
        "            fig.suptitle(f'Hyperparameter Importances for {model_name}', fontsize=12, color='black')\n",
        "\n",
        "            ax.xaxis.label.set_color('black')\n",
        "            ax.yaxis.label.set_color('black')\n",
        "            ax.tick_params(axis='x', colors='black')\n",
        "            ax.tick_params(axis='y', colors='black')\n",
        "\n",
        "            for text in ax.texts:\n",
        "                text.set_color('black')\n",
        "\n",
        "            if ax.legend_:\n",
        "                ax.legend().remove()\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while plotting the graph: {e}\")\n",
        "    else:\n",
        "        print(f\"Error: Study files not found at expected path: {optuna_dir}\")"
      ],
      "metadata": {
        "id": "nrHUxUPnDQ-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.9 Final Model Creation"
      ],
      "metadata": {
        "id": "lp6WnrPRpdxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline(model_name, X_train, y_train, X_val, y_val, X_test, y_test, best_hp, class_weights, dataset_name, save_root=SAVE_ROOT, device=DEVICE, num_labels=NUM_LABELS\n",
        "):\n",
        "    model_dir_name = model_name.replace(\"/\", \"_\")\n",
        "\n",
        "    experiment_dir = Path(save_root) / model_dir_name / dataset_name\n",
        "    model_folder = experiment_dir / \"final_model\"\n",
        "    model_folder.mkdir(parents=True, exist_ok=True)\n",
        "    print(\"Outputs will be saved to:\", model_folder)\n",
        "\n",
        "    model, tokenizer = init_model_and_tokenizer(\n",
        "        model_name,\n",
        "        num_labels=num_labels,\n",
        "        hidden_dropout_prob=best_hp.get(\"hidden_dropout_prob\"),\n",
        "        attention_dropout_prob=best_hp.get(\"attention_dropout_prob\")\n",
        "    )\n",
        "    model.to(device)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        SentimentDataset(X_train, y_train, tokenizer, max_len=MAX_LEN),\n",
        "        batch_size=best_hp.get(\"batch_size\", 32), shuffle=True, collate_fn=collate_fn,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=make_generator(SEED)\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        SentimentDataset(X_val, y_val, tokenizer, max_len=MAX_LEN),\n",
        "        batch_size=best_hp.get(\"batch_size\", 32), shuffle=False, collate_fn=collate_fn,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=make_generator(SEED)\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        SentimentDataset(X_test, y_test, tokenizer, max_len=MAX_LEN),\n",
        "        batch_size=best_hp.get(\"batch_size\", 32), shuffle=False, collate_fn=collate_fn,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=make_generator(SEED)\n",
        "    )\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    optimizer = AdamW(\n",
        "        model.parameters(),\n",
        "        lr=best_hp.get(\"lr\", 2e-5),\n",
        "        weight_decay=best_hp.get(\"weight_decay\", 0.0)\n",
        "    )\n",
        "    total_steps = len(train_loader) * best_hp.get(\"epochs\", 3)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=int(total_steps * best_hp.get(\"warmup_ratio\", 0.0)),\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # FINAL MODEL TRAINING\n",
        "    training_history = []\n",
        "\n",
        "    for epoch in range(best_hp.get(\"epochs\", 3)):\n",
        "        val_f1, train_loss, val_loss = train_validate_model(\n",
        "            model, train_loader, val_loader, optimizer, scheduler, loss_fn, device\n",
        "        )\n",
        "\n",
        "        training_history.append({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": float(train_loss),\n",
        "            \"val_loss\": float(val_loss),\n",
        "            \"val_weighted_f1\": float(val_f1)\n",
        "        })\n",
        "\n",
        "    model.save_pretrained(model_folder)\n",
        "    tokenizer.save_pretrained(model_folder)\n",
        "    print(\"✅ Saved final model to:\", model_folder)\n",
        "\n",
        "    history_csv_path = model_folder / \"training_history.csv\"\n",
        "    pd.DataFrame(training_history).to_csv(history_csv_path, index=False)\n",
        "    print(\"✅ Saved training history to:\", history_csv_path)\n",
        "\n",
        "    # EVALUATIONS\n",
        "    train_preds, train_trues = evaluate_model(model, train_loader, device)\n",
        "    val_preds, val_trues = evaluate_model(model, val_loader, device)\n",
        "    test_preds, test_trues = evaluate_model(model, test_loader, device)\n",
        "\n",
        "    train_cr_df = create_classification_report(train_trues, train_preds)\n",
        "    val_cr_df = create_classification_report(val_trues, val_preds)\n",
        "    test_cr_df = create_classification_report(test_trues, test_preds)\n",
        "\n",
        "    train_cr_df[\"dataset\"] = \"train\"\n",
        "    val_cr_df[\"dataset\"] = \"validation\"\n",
        "    test_cr_df[\"dataset\"] = \"test\"\n",
        "\n",
        "    all_reports_df = pd.concat([train_cr_df, val_cr_df, test_cr_df])\n",
        "    all_reports_df.to_csv(model_folder / \"all_classification_reports.csv\", index=False)\n",
        "    print(\"✅ Saved classification reports.\")\n",
        "    create_confusion_matrix(test_trues, test_preds, model_folder / \"confusion_matrix.png\")\n",
        "    print(\"✅ Saved confusion matrix.\")\n",
        "\n",
        "    summary = {\n",
        "        \"model_name\": model_name,\n",
        "        \"dataset_name\": dataset_name,\n",
        "        \"n_train\": len(X_train),\n",
        "        \"n_val\": len(X_val),\n",
        "        \"n_test\": len(X_test),\n",
        "        \"train_weighted_f1\": float(f1_score(train_trues, train_preds, average='weighted')),\n",
        "        \"val_weighted_f1\": float(f1_score(val_trues, val_preds, average='weighted')),\n",
        "        \"test_weighted_f1\": float(f1_score(test_trues, test_preds, average='weighted')),\n",
        "        \"train_accuracy\": float((np.array(train_preds) == np.array(train_trues)).mean()),\n",
        "        \"val_accuracy\": float((np.array(val_preds) == np.array(val_trues)).mean()),\n",
        "        \"test_accuracy\": float((np.array(test_preds) == np.array(test_trues)).mean())\n",
        "    }\n",
        "\n",
        "    summary_json_path = model_folder / \"summary.json\"\n",
        "    with open(summary_json_path, \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "    pd.json_normalize(summary).to_csv(model_folder / \"summary_metrics.csv\", index=False)\n",
        "\n",
        "    print(f\"✅ Pipeline Completed for {model_name} [{dataset_name}].\")\n",
        "\n",
        "    del model, tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "\n",
        "    return {\n",
        "        \"summary\": summary,\n",
        "        \"train_classification_report\": train_cr_df,\n",
        "        \"validation_classification_report\": val_cr_df,\n",
        "        \"test_classification_report\": test_cr_df,\n",
        "        \"model_dir\": str(model_folder)\n",
        "    }"
      ],
      "metadata": {
        "id": "4gXu8jJ9ncqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Run Optuna and Final Model Pipeline"
      ],
      "metadata": {
        "id": "iob26aV0-gXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1. indobenchmark/indobert-base-p1"
      ],
      "metadata": {
        "id": "Gaj_kowh5wfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod_indo_base_p1 = 'indobenchmark/indobert-base-p1'"
      ],
      "metadata": {
        "id": "K9suTV6C5wfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.1. Original"
      ],
      "metadata": {
        "id": "YlSD0L5H5wfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hp_indo_base_p1 = run_optuna_for_model(\n",
        "    model_name=mod_indo_base_p1,\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"original\"\n",
        ")"
      ],
      "metadata": {
        "id": "i1cez90d5wfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(\n",
        "    model_name=mod_indo_base_p1,\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=hp_indo_base_p1,\n",
        "    class_weights=class_weights,\n",
        "    dataset_name=\"original\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "O-Lfs4ub5wfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_indo_base_p1,\n",
        "    dataset_name=\"original\"\n",
        ")"
      ],
      "metadata": {
        "id": "4HmxDatqIZwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.2. ROS"
      ],
      "metadata": {
        "id": "MwKPnbFj5wfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hp_indo_base_p1_ros = run_optuna_for_model(\n",
        "    model_name=mod_indo_base_p1,\n",
        "    X_train=X_train_ros,\n",
        "    y_train=y_train_ros,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights_ros,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"ROS\"\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "D-ouxG2-5wfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(\n",
        "    model_name=mod_indo_base_p1,\n",
        "    X_train=X_train_ros,\n",
        "    y_train=y_train_ros,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=hp_indo_base_p1_ros,\n",
        "    class_weights=class_weights_ros,\n",
        "    dataset_name=\"ROS\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8C1T9rlB5wfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_indo_base_p1,\n",
        "    dataset_name=\"ROS\"\n",
        ")"
      ],
      "metadata": {
        "id": "MvcyZARAIr4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.3. ROS+NCL"
      ],
      "metadata": {
        "id": "crZyZZp25wfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hp_indo_base_p1_ros_ncl = run_optuna_for_model(\n",
        "    model_name=mod_indo_base_p1,\n",
        "    X_train=X_train_ros_ncl,\n",
        "    y_train=y_train_ros_ncl,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights_ros_ncl,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"ROS-NCL\"\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rktDmfS65wfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_indo_2_ros_ncl = pipeline(\n",
        "    model_name=mod_indo_base_p1,\n",
        "    X_train=X_train_ros_ncl,\n",
        "    y_train=y_train_ros_ncl,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=hp_indo_base_p1_ros_ncl,\n",
        "    class_weights=class_weights_ros_ncl,\n",
        "    dataset_name=\"ROS-NCL\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "id": "qjKDBZn95wfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_indo_base_p1,\n",
        "    dataset_name=\"ROS-NCL\"\n",
        ")"
      ],
      "metadata": {
        "id": "k_RbvQdbItFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. indobenchmark/indobert-base-p2"
      ],
      "metadata": {
        "id": "uqXz5S-i5wfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod_indo_base_p2 = 'indobenchmark/indobert-base-p2'"
      ],
      "metadata": {
        "id": "3K3vMGg6Tl5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.1. Original"
      ],
      "metadata": {
        "id": "62XlBy4nTl5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hp_indo_base_p2 = run_optuna_for_model(\n",
        "    model_name=mod_indo_base_p2,\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"original\"\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KzIl_hQ5Tl5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(\n",
        "    model_name=mod_indo_base_p2,\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=hp_indo_base_p2,\n",
        "    class_weights=class_weights,\n",
        "    dataset_name=\"original\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LvMeGe_2Tl5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_indo_base_p2,\n",
        "    dataset_name=\"original\"\n",
        ")"
      ],
      "metadata": {
        "id": "-oz_nzjtIvuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.2. ROS"
      ],
      "metadata": {
        "id": "nMpHVUWrTl5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hp_indo_base_p2_ros = run_optuna_for_model(\n",
        "    model_name=mod_indo_base_p2,\n",
        "    X_train=X_train_ros,\n",
        "    y_train=y_train_ros,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights_ros,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"ROS\"\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Fizd3Ci8Tl5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(\n",
        "    model_name=mod_indo_base_p2,\n",
        "    X_train=X_train_ros,\n",
        "    y_train=y_train_ros,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=hp_indo_base_p2_ros,\n",
        "    class_weights=class_weights_ros,\n",
        "    dataset_name=\"ROS\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IYOh1kuCTl5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_indo_base_p2,\n",
        "    dataset_name=\"ROS\"\n",
        ")"
      ],
      "metadata": {
        "id": "BkmrpcVXIxIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.3. ROS+NCL"
      ],
      "metadata": {
        "id": "lTIBEnudTl5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hp_indo_base_p2_ros_ncl = run_optuna_for_model(\n",
        "    model_name=mod_indo_base_p2,\n",
        "    X_train=X_train_ros_ncl,\n",
        "    y_train=y_train_ros_ncl,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights_ros_ncl,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"ROS-NCL\"\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_E2myfSyTl5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_indo_2_ros_ncl = pipeline(\n",
        "    model_name=mod_indo_base_p2,\n",
        "    X_train=X_train_ros_ncl,\n",
        "    y_train=y_train_ros_ncl,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=hp_indo_base_p2_ros_ncl,\n",
        "    class_weights=class_weights_ros_ncl,\n",
        "    dataset_name=\"ROS-NCL\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "id": "N7WD3x75Tl5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_indo_base_p2,\n",
        "    dataset_name=\"ROS-NCL\"\n",
        ")"
      ],
      "metadata": {
        "id": "o4PmhStaIyg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3. indobenchmark/indobert-lite-base-p1"
      ],
      "metadata": {
        "id": "W_44D3mh-kyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod_indo_lite_p1 = 'indobenchmark/indobert-lite-base-p1'"
      ],
      "metadata": {
        "id": "PrnXRfb--zV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.1. Original"
      ],
      "metadata": {
        "id": "L5Jdje7_BNAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp_indo_2_ori = run_optuna_for_model(\n",
        "    model_name=mod_indo_lite_p1,\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"original\"\n",
        ")"
      ],
      "metadata": {
        "id": "jjJ5IbQkGEZ4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_indo_2_ori = pipeline(\n",
        "    model_name=mod_indo_lite_p1,\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=best_hp_indo_2_ori,\n",
        "    class_weights=class_weights,\n",
        "    dataset_name=\"original\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "id": "psXZZnopGEZ5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_indo_lite_p1,\n",
        "    dataset_name=\"original\"\n",
        ")"
      ],
      "metadata": {
        "id": "YnYQZge12PDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.2. ROS"
      ],
      "metadata": {
        "id": "KWwOCNy0BWfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp_indo_2_ros = run_optuna_for_model(\n",
        "    model_name=mod_indo_lite_p1,\n",
        "    X_train=X_train_ros,\n",
        "    y_train=y_train_ros,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights_ros,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"ROS\"\n",
        ")"
      ],
      "metadata": {
        "id": "X2mMUZXxObP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_indo_2_ros = pipeline(\n",
        "    model_name=mod_indo_lite_p1,\n",
        "    X_train=X_train_ros,\n",
        "    y_train=y_train_ros,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=best_hp_indo_2_ros,\n",
        "    class_weights=class_weights_ros,\n",
        "    dataset_name=\"ROS\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "id": "xSmVTSE6ObP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_indo_lite_p1,\n",
        "    dataset_name=\"ROS\"\n",
        ")"
      ],
      "metadata": {
        "id": "XUhaI4SjI3Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.3. ROS+NCL"
      ],
      "metadata": {
        "id": "m-OuTD6ZBRTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp_indo_2_ros_ncl = run_optuna_for_model(\n",
        "    model_name=mod_indo_lite_p1,\n",
        "    X_train=X_train_ros_ncl,\n",
        "    y_train=y_train_ros_ncl,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights_ros_ncl,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"ROS-NCL\"\n",
        ")"
      ],
      "metadata": {
        "id": "hqo4tSsFOjrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_indo_2_ros_ncl = pipeline(\n",
        "    model_name=mod_indo_lite_p1,\n",
        "    X_train=X_train_ros_ncl,\n",
        "    y_train=y_train_ros_ncl,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=best_hp_indo_2_ros_ncl,\n",
        "    class_weights=class_weights_ros_ncl,\n",
        "    dataset_name=\"ROS-NCL\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "id": "7p_QuZn-OkxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_indo_lite_p1,\n",
        "    dataset_name=\"ROS-NCL\"\n",
        ")"
      ],
      "metadata": {
        "id": "0ZSxJVA3I4-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4. indobenchmark/indobert-lite-base-p2"
      ],
      "metadata": {
        "id": "jJBUsSXI68uZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod_indo_lite_p2 = \"indobenchmark/indobert-lite-base-p2\""
      ],
      "metadata": {
        "id": "empWENdmk5pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.1. Original"
      ],
      "metadata": {
        "id": "V5JDx1EuB0AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp_indo_ori = run_optuna_for_model(\n",
        "    model_name=mod_indo_lite_p2,\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"original\"\n",
        ")"
      ],
      "metadata": {
        "id": "HqrFJ-H5k_kl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_indo_ori = pipeline(\n",
        "    model_name=mod_indo_lite_p2,\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=best_hp_indo_ori,\n",
        "    class_weights=class_weights,\n",
        "    dataset_name=\"original\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "id": "l9GJ45IWlHPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_indo_lite_p2,\n",
        "    dataset_name=\"original\"\n",
        ")"
      ],
      "metadata": {
        "id": "J-MIJEqKI6tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.2. ROS"
      ],
      "metadata": {
        "id": "gka-Rq70B5aA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp_indo_ros = run_optuna_for_model(\n",
        "    model_name=mod_indo_lite_p2,\n",
        "    X_train=X_train_ros,\n",
        "    y_train=y_train_ros,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights_ros,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"ROS\"\n",
        ")"
      ],
      "metadata": {
        "id": "B4-YjRmpWD1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_indo_ros = pipeline(\n",
        "    model_name=mod_indo_lite_p2,\n",
        "    X_train=X_train_ros,\n",
        "    y_train=y_train_ros,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=best_hp_indo_ros,\n",
        "    class_weights=class_weights_ros,\n",
        "    dataset_name=\"ROS\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "id": "OkpvVcvnWD1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_indo_lite_p2,\n",
        "    dataset_name=\"ROS\"\n",
        ")"
      ],
      "metadata": {
        "id": "90KPKhEF2gyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_indo_lite_p2,\n",
        "    dataset_name=\"ROS\"\n",
        ")"
      ],
      "metadata": {
        "id": "LAVMD289I9n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.3. ROS+NCL"
      ],
      "metadata": {
        "id": "3dhdFHRaB7Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp_indo_ros_ncl = run_optuna_for_model(\n",
        "    model_name=mod_indo_lite_p2,\n",
        "    X_train=X_train_ros_ncl,\n",
        "    y_train=y_train_ros_ncl,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights_ros_ncl,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"ROS-NCL\"\n",
        ")"
      ],
      "metadata": {
        "id": "8CrmjhYD3VVq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_indo_ros_ncl = pipeline(\n",
        "    model_name=mod_indo_lite_p2,\n",
        "    X_train=X_train_ros_ncl,\n",
        "    y_train=y_train_ros_ncl,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=best_hp_indo_ros_ncl,\n",
        "    class_weights=class_weights_ros_ncl,\n",
        "    dataset_name=\"ROS-NCL\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2HZGL-uq3V7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_indo_lite_p2,\n",
        "    dataset_name=\"ROS-NCL\"\n",
        ")"
      ],
      "metadata": {
        "id": "S-tJE6Oa2iKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_indo_lite_p2,\n",
        "    dataset_name=\"ROS-NCL\"\n",
        ")"
      ],
      "metadata": {
        "id": "AYSyBKoJI-8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5. LazarusNLP/NusaBERT-base"
      ],
      "metadata": {
        "id": "ad_X3v4L6_iD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod_nusa = \"LazarusNLP/NusaBERT-base\""
      ],
      "metadata": {
        "id": "3UxG8rSU33Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5.1. Original"
      ],
      "metadata": {
        "id": "5j6con3bB-Vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp_nusa_ori = run_optuna_for_model(\n",
        "    model_name=mod_nusa,\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"original\"\n",
        ")"
      ],
      "metadata": {
        "id": "nCrpv6kHWeBV",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_nusa_ori = pipeline(\n",
        "    model_name=mod_nusa,\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=best_hp_nusa_ori,\n",
        "    class_weights=class_weights,\n",
        "    dataset_name=\"original\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "id": "9Aad1RbpWeBW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_nusa,\n",
        "    dataset_name=\"original\"\n",
        ")"
      ],
      "metadata": {
        "id": "cXrtOojm2kss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5.2. ROS"
      ],
      "metadata": {
        "id": "aeQcYeyeCANe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp_nusa_ros = run_optuna_for_model(\n",
        "    model_name=mod_nusa,\n",
        "    X_train=X_train_ros,\n",
        "    y_train=y_train_ros,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights_ros,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"ROS\"\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OXk23Ef53LpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_nusa_ros = pipeline(\n",
        "    model_name=mod_nusa,\n",
        "    X_train=X_train_ros,\n",
        "    y_train=y_train_ros,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=best_hp_nusa_ros,\n",
        "    class_weights=class_weights_ros,\n",
        "    dataset_name=\"ROS\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "id": "YycY0XH83LpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_nusa,\n",
        "    dataset_name=\"ROS\"\n",
        ")"
      ],
      "metadata": {
        "id": "CaNxed0MJCQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.3. ROS+NCL"
      ],
      "metadata": {
        "id": "OekqPBT_CB1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp_nusa_ros_ncl = run_optuna_for_model(\n",
        "    model_name=mod_nusa,\n",
        "    X_train=X_train_ros_ncl,\n",
        "    y_train=y_train_ros_ncl,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    n_trials=20,\n",
        "    class_weights=class_weights_ros_ncl,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"ROS-NCL\"\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "W_cUCY7ECE_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_nusa_ros_ncl = pipeline(\n",
        "    model_name=mod_nusa,\n",
        "    X_train=X_train_ros_ncl,\n",
        "    y_train=y_train_ros_ncl,\n",
        "    X_val=X_val,\n",
        "    y_val=y_val,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    best_hp=best_hp_nusa_ros_ncl,\n",
        "    class_weights=class_weights_ros_ncl,\n",
        "    dataset_name=\"ROS-NCL\",\n",
        "    save_root=SAVE_ROOT,\n",
        "    device=DEVICE,\n",
        "    num_labels=NUM_LABELS\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mq05mdPZCE_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hp_importance_graph(\n",
        "    save_root=SAVE_ROOT,\n",
        "    model_name=mod_nusa,\n",
        "    dataset_name=\"ROS-NCL\"\n",
        ")"
      ],
      "metadata": {
        "id": "fxUBBsV8JDbq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}