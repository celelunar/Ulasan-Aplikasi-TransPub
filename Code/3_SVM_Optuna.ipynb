{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pPlXBhP1Nocu",
        "ZMZT6e6Kiuv2",
        "_5u4alfdjrYL",
        "U7LjLpeHN2Pj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPlXBhP1Nocu"
      },
      "source": [
        "# 1. Install and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "kmLxIG6bWDLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRLbLRTtKSq4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from google.colab import drive\n",
        "\n",
        "import optuna\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6ZDKwJfNrdL"
      },
      "source": [
        "# 2. Environment Settings and Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKwwrTUbCEYY"
      },
      "source": [
        "## 2.1. Set Seed for Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "1xohckDb45Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRNNX-IxiSua"
      },
      "source": [
        "## 2.3. Manage Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMZT6e6Kiuv2"
      },
      "source": [
        "### 2.3.1. Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QArK99vYixSF"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck2cH-kViyOR"
      },
      "source": [
        "### 2.3.2. Set Folder Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsFYWGlci9zI"
      },
      "outputs": [],
      "source": [
        "# Datasets\n",
        "READ_PATH = '/content/drive/MyDrive/Bach_Thesis/Dataset/'\n",
        "\n",
        "# Models\n",
        "SAVE_ROOT = \"/content/drive/MyDrive/Bach_Thesis/Models/SA_Optuna\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5u4alfdjrYL"
      },
      "source": [
        "## 2.4. Initialize Global Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXNA-w-Zgq-M"
      },
      "outputs": [],
      "source": [
        "LABELS = [0,1]\n",
        "TARGET_NAMES = ['negative','positive']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GKUx0J5jycQ"
      },
      "source": [
        "## 2.5. Initialize Datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_ori = pd.read_csv(f\"{READ_PATH}Train2lab.csv\")\n",
        "df_train_ros = pd.read_csv(f\"{READ_PATH}Train_ROS2lab.csv\")\n",
        "df_train_ros_ncl = pd.read_csv(f\"{READ_PATH}Train_ROS_NCL2lab.csv\")"
      ],
      "metadata": {
        "id": "EM9-Hl9yN7lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val = pd.read_csv(f\"{READ_PATH}Validation2lab.csv\")\n",
        "df_test = pd.read_csv(f\"{READ_PATH}Test2lab.csv\")"
      ],
      "metadata": {
        "id": "5ex3WmUgOdYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7LjLpeHN2Pj"
      },
      "source": [
        "# 3. Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_classification_report(y_true, y_pred):\n",
        "    cr = classification_report(y_true, y_pred, labels=LABELS, target_names=TARGET_NAMES, zero_division=0, output_dict=True)\n",
        "    df_cr = pd.DataFrame(cr).transpose().reset_index().rename(columns={'index':'label'})\n",
        "    for col in df_cr.select_dtypes(include=['float']).columns:\n",
        "        df_cr[col] = df_cr[col].round(4)\n",
        "\n",
        "    return df_cr"
      ],
      "metadata": {
        "id": "TtVu5nvm5MjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_confusion_matrix(y_true, y_pred, save_path_png):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=TARGET_NAMES, yticklabels=TARGET_NAMES)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path_png, dpi=150)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "iFjJtctk5Ozb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_svm(trial, df_train, df_val, seed):\n",
        "    C = trial.suggest_float('C', 1e-3, 1e2, log=True)\n",
        "\n",
        "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly', 'sigmoid'])\n",
        "\n",
        "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
        "\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        ngram_range=(1,2),\n",
        "        sublinear_tf=True\n",
        "    )\n",
        "    X_train = vectorizer.fit_transform(df_train[\"cleaned_content\"])\n",
        "    y_train = df_train[\"sentiment\"]\n",
        "    X_val = vectorizer.transform(df_val[\"cleaned_content\"])\n",
        "    y_val = df_val[\"sentiment\"]\n",
        "\n",
        "    model = SVC(\n",
        "        C=C,\n",
        "        kernel=kernel,\n",
        "        gamma=gamma,\n",
        "        random_state=seed,\n",
        "        probability=True\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_val)\n",
        "\n",
        "    return f1_score(y_val, preds, average=\"weighted\", zero_division=0)"
      ],
      "metadata": {
        "id": "28ANnO0xU26l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_optuna_svm(df_train, df_val, seed, n_trials, save_root, dataset_name=\"dataset\"):\n",
        "    experiment_dir = Path(save_root) / \"SVM_2\" / dataset_name\n",
        "    study_dir = experiment_dir / \"optuna_study\"\n",
        "    study_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    storage_path = study_dir / \"study.db\"\n",
        "    study_name_path = study_dir / \"study_name.txt\"\n",
        "    storage_uri = f\"sqlite:///{storage_path}\"\n",
        "\n",
        "    if storage_path.exists() and study_name_path.exists():\n",
        "        study_name = study_name_path.read_text().strip()\n",
        "        study = optuna.load_study(study_name=study_name, storage=storage_uri)\n",
        "        print(f\"Resuming Optuna study: {study_name}\")\n",
        "    else:\n",
        "        study_name = \"svm_opt_\" + dataset_name\n",
        "        study_name_path.write_text(study_name)\n",
        "        print(f\"Creating new Optuna study: {study_name}\")\n",
        "        study = optuna.create_study(\n",
        "            study_name=study_name,\n",
        "            direction=\"maximize\",\n",
        "            storage=storage_uri,\n",
        "            load_if_exists=True\n",
        "        )\n",
        "\n",
        "    study.optimize(\n",
        "        lambda trial: objective_svm(trial, df_train, df_val, seed),\n",
        "        n_trials=n_trials\n",
        "    )\n",
        "\n",
        "    print(\"Best F1:\", study.best_value)\n",
        "    print(\"Best Params:\", study.best_params)\n",
        "    return study.best_params"
      ],
      "metadata": {
        "id": "_FG2rclyVroJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_pipeline(df_train, df_val, df_test, best_hp, seed, save_root, dataset_name=\"dataset\"):\n",
        "    experiment_dir = Path(save_root) / \"SVM_2\" / dataset_name\n",
        "    final_dir = experiment_dir / \"final_model\"\n",
        "    final_dir.mkdir(parents=True, exist_ok=True)\n",
        "    print(\"Saving outputs to:\", final_dir)\n",
        "\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        ngram_range=(1,2),\n",
        "        sublinear_tf=True\n",
        "    )\n",
        "    X_train = vectorizer.fit_transform(df_train[\"cleaned_content\"])\n",
        "    y_train = df_train[\"sentiment\"]\n",
        "    X_val = vectorizer.transform(df_val[\"cleaned_content\"])\n",
        "    y_val = df_val[\"sentiment\"]\n",
        "    X_test = vectorizer.transform(df_test[\"cleaned_content\"])\n",
        "    y_test = df_test[\"sentiment\"]\n",
        "\n",
        "    model = SVC(\n",
        "        C=best_hp[\"C\"],\n",
        "        kernel=best_hp[\"kernel\"],\n",
        "        gamma=best_hp.get(\"gamma\", \"scale\"),\n",
        "        random_state=seed,\n",
        "        probability=True\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    train_preds = model.predict(X_train)\n",
        "    val_preds = model.predict(X_val)\n",
        "    test_preds = model.predict(X_test)\n",
        "\n",
        "    train_cr_df = create_classification_report(y_train, train_preds)\n",
        "    val_cr_df = create_classification_report(y_val, val_preds)\n",
        "    test_cr_df = create_classification_report(y_test, test_preds)\n",
        "\n",
        "    train_cr_df.to_csv(final_dir / \"classification_report_train.csv\", index=False)\n",
        "    val_cr_df.to_csv(final_dir / \"classification_report_val.csv\", index=False)\n",
        "    test_cr_df.to_csv(final_dir / \"classification_report_test.csv\", index=False)\n",
        "\n",
        "    create_confusion_matrix(y_train, train_preds, final_dir / \"cm_train.png\")\n",
        "    create_confusion_matrix(y_val, val_preds, final_dir / \"cm_val.png\")\n",
        "    create_confusion_matrix(y_test, test_preds, final_dir / \"cm_test.png\")\n",
        "\n",
        "    summary = {\n",
        "        \"model\": \"SVM\",\n",
        "        \"dataset\": dataset_name,\n",
        "        \"n_train\": len(df_train),\n",
        "        \"n_val\": len(df_val),\n",
        "        \"n_test\": len(df_test),\n",
        "        \"train_weighted_f1\": round(f1_score(y_train, train_preds, average='weighted'), 4),\n",
        "        \"val_weighted_f1\": round(f1_score(y_val, val_preds, average='weighted'), 4),\n",
        "        \"test_weighted_f1\": round(f1_score(y_test, test_preds, average='weighted'), 4),\n",
        "        \"train_accuracy\": round((train_preds == y_train).mean(), 4),\n",
        "        \"val_accuracy\": round((val_preds == y_val).mean(), 4),\n",
        "        \"test_accuracy\": round((test_preds == y_test).mean(), 4),\n",
        "        \"best_hp\": best_hp\n",
        "    }\n",
        "\n",
        "    with open(final_dir / \"summary.json\", \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "    pd.json_normalize(summary).to_csv(final_dir / \"summary_metrics.csv\", index=False)\n",
        "\n",
        "    joblib.dump(model, final_dir / \"svm_model.pkl\")\n",
        "    joblib.dump(vectorizer, final_dir / \"tfidf.pkl\")\n",
        "\n",
        "    print(\"âœ… SVM pipeline completed.\")\n",
        "    print(\"Model saved to:\", final_dir)\n",
        "\n",
        "    return {\n",
        "        \"summary\": summary,\n",
        "        \"train_report\": train_cr_df,\n",
        "        \"validation_report\": val_cr_df,\n",
        "        \"test_report\": test_cr_df,\n",
        "        \"model_dir\": str(final_dir)\n",
        "    }"
      ],
      "metadata": {
        "id": "rweNlVLkVtuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Run Models"
      ],
      "metadata": {
        "id": "mbWJYsVi5ezR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text_column(df, text_col=\"cleaned_content\"):\n",
        "    df[text_col] = df[text_col].fillna(\"\").astype(str)\n",
        "    return df\n",
        "\n",
        "df_train_ori = clean_text_column(df_train_ori, \"cleaned_content\")\n",
        "df_train_ros = clean_text_column(df_train_ros, \"cleaned_content\")\n",
        "df_train_ros_ncl = clean_text_column(df_train_ros_ncl, \"cleaned_content\")\n",
        "df_val = clean_text_column(df_val, \"cleaned_content\")\n",
        "df_test = clean_text_column(df_test, \"cleaned_content\")"
      ],
      "metadata": {
        "id": "VdIMUaQ4WhFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## original"
      ],
      "metadata": {
        "id": "OczOqFsgWkEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp_ori = run_optuna_svm(\n",
        "    df_train=df_train_ori,\n",
        "    df_val=df_val,\n",
        "    seed=SEED,\n",
        "    n_trials=20,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"original\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "1NzNuCN15hmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_ori = svm_pipeline(\n",
        "    df_train=df_train_ori,\n",
        "    df_val=df_val,\n",
        "    df_test=df_test,\n",
        "    best_hp=best_hp_ori,\n",
        "    seed=SEED,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"original\"\n",
        ")"
      ],
      "metadata": {
        "id": "mfxag-1d5jL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ros"
      ],
      "metadata": {
        "id": "BN4EmsvMd4X5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp_ros = run_optuna_svm(\n",
        "    df_train=df_train_ros,\n",
        "    df_val=df_val,\n",
        "    seed=SEED,\n",
        "    n_trials=20,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"ROS\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "6V36JEryjqoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_ros = svm_pipeline(\n",
        "    df_train=df_train_ros,\n",
        "    df_val=df_val,\n",
        "    df_test=df_test,\n",
        "    best_hp=best_hp_ros,\n",
        "    seed=SEED,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"ROS\"\n",
        ")"
      ],
      "metadata": {
        "id": "SOT82e7FjqoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ros-ncl"
      ],
      "metadata": {
        "id": "HnPvFBQlVgai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp_ros_ncl = run_optuna_svm(\n",
        "    df_train=df_train_ros_ncl,\n",
        "    df_val=df_val,\n",
        "    seed=SEED,\n",
        "    n_trials=20,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"ROS-NCL\"\n",
        ")"
      ],
      "metadata": {
        "id": "iYljmzrBd4nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_ros_ncl = svm_pipeline(\n",
        "    df_train=df_train_ros_ncl,\n",
        "    df_val=df_val,\n",
        "    df_test=df_test,\n",
        "    best_hp=best_hp_ros_ncl,\n",
        "    seed=SEED,\n",
        "    save_root=SAVE_ROOT,\n",
        "    dataset_name=\"ROS-NCL\"\n",
        ")"
      ],
      "metadata": {
        "id": "XHgCPRNxd9QR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}